{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this notebook we will use the preprocessing tools built for this project to convert the images in our dataset to a format compatible with neural network modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from module4_scripts.dir_constructor import DataDirectoryConstructor\n",
    "from module4_scripts.reader import ImageReader\n",
    "from module4_scripts.preprocessor import Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = [\"NORMAL\", \"PNEUMONIA\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Directory Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is sourced from the Kaggle link here: https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step in this project is to download and organize the data in the directory. What we want is for the data to be split into train, validation and test splits, using appropriate set size allocations. Within each set, we'll have subsets for the two classes in the dataset, \"NORMAL\", and \"PNEUMONIA\". We can use the DataDirectoryConstructor class to do exactly this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Directories:\n",
      "\tdata/NORMAL/\n",
      "\tdata/PNEUMONIA/\n",
      "\n",
      "Splits: \n",
      "\tTrain size: 0.8 \n",
      "\tTest size: 0.1 \n",
      "\tValidation size: 0.1\n",
      "\n",
      "Generated Train data directory\n",
      "Generated Test data directory\n",
      "Generated Val data directory\n"
     ]
    }
   ],
   "source": [
    "DataDirectoryConstructor(\n",
    "    directory=\"data/\",\n",
    "    subdirs=LABELS,\n",
    "    train_size=0.8,\n",
    "    test_size=0.1,\n",
    "    val_size=0.1\n",
    ").split_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our data directory set up, the next step is to read the images and create image generators for later preprocessing. We can use the ImageReader class for this. Note that this class also creates an additonal generator for generating augmented training data, so we can expand our training set for modeling. More info on how this class works can be found in its dosctrings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4685 images belonging to 2 classes.\n",
      "Found 4685 images belonging to 2 classes.\n",
      "Found 586 images belonging to 2 classes.\n",
      "Found 585 images belonging to 2 classes.\n",
      "\n",
      "=== Classes ===\n",
      "NORMAL: 0\n",
      "PNEUMONIA: 1\n",
      "\n",
      "=== Directory Breakdown ===\n",
      " ________________________________________\n",
      "Train\n",
      "\tNORMAL:\n",
      "\t\tCount: 1265\n",
      "\t\tProportion: 0.27\n",
      "\tPNEUMONIA:\n",
      "\t\tCount: 3420\n",
      "\t\tProportion: 0.73\n",
      "________________________________________\n",
      "Test\n",
      "\tNORMAL:\n",
      "\t\tCount: 158\n",
      "\t\tProportion: 0.27\n",
      "\tPNEUMONIA:\n",
      "\t\tCount: 428\n",
      "\t\tProportion: 0.73\n",
      "________________________________________\n",
      "Validation\n",
      "\tNORMAL:\n",
      "\t\tCount: 160\n",
      "\t\tProportion: 0.27\n",
      "\tPNEUMONIA:\n",
      "\t\tCount: 425\n",
      "\t\tProportion: 0.73\n",
      "________________________________________\n"
     ]
    }
   ],
   "source": [
    "#create ImageReader instance object\n",
    "image_reader = ImageReader()\n",
    "#read the images, create the generators\n",
    "image_reader.read()\n",
    "#display summary report of image reading\n",
    "image_reader.display_read_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The display_read_summary method displays some info of the data directory. We can see the structure of the directory and the counts and proportions of the images of each class. It's evident that there is some class imbalance present in the dataset. This can be addressed later on during modeling when we apply class weighting. (Note that the count of the training set will be proportionally doubled when we apply training data augmentation). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have read the images, we have to transform these images into data types that can be interpreted by the model,  numerical arrays. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brief overview for how his will work:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computers read images as 3D tensors, where each 2D matrix represents a color. The colors are red, green, and blue - thus the tensor is a stack of 3 matrices. The dimensions of the 2D matrices are equal to the pixel dimensions of the image, and each element in a matrix represents a pixel color intensity, and this value can be between 0 and 255. The combination of red, green, and blue pixel intensities result in the color you see on one pixel of an image (of course, if the pixel dimensions of an image are very high, the human eye can't possibly see one pixel). The Preprocessor class can convert images to arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending augmented data to Train set\n",
      "\n",
      "=== Processing Train set ===\n",
      "Original shapes: \n",
      "\tImages: (9370, 256, 256, 3) \n",
      "\tLabels: (9370,)\n",
      "Reshaped shapes: \n",
      "\tImages: (9370, 196608) \n",
      "\tLabels: (9370, 1)\n",
      "\n",
      "=== Processing Test set ===\n",
      "Original shapes: \n",
      "\tImages: (586, 256, 256, 3) \n",
      "\tLabels: (586,)\n",
      "Reshaped shapes: \n",
      "\tImages: (586, 196608) \n",
      "\tLabels: (586, 1)\n",
      "\n",
      "=== Processing Validation set ===\n",
      "Original shapes: \n",
      "\tImages: (585, 256, 256, 3) \n",
      "\tLabels: (585,)\n",
      "Reshaped shapes: \n",
      "\tImages: (585, 196608) \n",
      "\tLabels: (585, 1)\n"
     ]
    }
   ],
   "source": [
    "#instantiate a Preprocessor instance object\n",
    "preprocessor = Preprocessor(**vars(image_reader))\n",
    "#preprocess the data, set the augment_data argument \n",
    "#to True so as to increase size of training data\n",
    "preprocessor.preprocess(augment_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different kinds of models require different input shapes. The densely connected neural networks that we'll work with require that input shapes are 2D, and the convolutional neural networks that we'll work with require that input shapes are 4D. The 'preprocessor' object now holds all data in both 2D and 4D form, which we can use for model building. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To end the preprocessing stage, we'll compress and save all the sets in the local directory \"npy/\" as an .npz file. (This compressed file is close to ~3GB, so it was not uploaded to the repo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressing and saving all sets to npy/arrays.npz\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "preprocessor.save_arrays(path=\"npy/arrays\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
